import requests
import json
import traceback
import math
from pyspark import SparkConf
from pyspark.sql import SparkSession


def fetch_data_from_mockaroo(url:str, schema:str, no_of_records:int):
    """
    This method is used to fetch data from Mockaroo api endpoints.

    Parametes:
    ----------
    url: str, endpoint of mockaroo
    no_of_records: int, Number of records you want to fetch from Mockaroo endpoint

    Returns:
    --------
    List containing the records generated by Mockaroo
    
    """
    
    if isinstance(no_of_records, int)  is False:
        raise TypeError("Argument no_of_records should be of Integer type")

    #Limiting the fetch to 20K as mockaroo free account limitations
    if no_of_records>0 and no_of_records<=20000:
        try:
            #Free account limit is 1000
            step_size = 1000
            balance = 0
            consolidated_data = []
            offset = min(no_of_records, step_size)
            for i in range(1,math.ceil(no_of_records/step_size)+1):
                parameters = {'key':'fe1375b0', 'count':offset, 'schema' : schema}
                response = requests.post(url, params =parameters )
                if response.status_code == 200:
                    data = json.loads(response.text)
                    consolidated_data.extend(data) 
                else:
                    print("Failed to fetch data for batch: ",i)
                    print("Error:", response.text)

                balance = no_of_records - (step_size*i)
                offset = min(balance, step_size)
        except Exception as e:
            print("Error occured while trying to fetch data from Mockaroo")
            print(traceback.format_exc())
        else:
            return consolidated_data
            
    else:
        raise ValueError("Argument no_of_records should be in the range 0 and 20000")


def create_spark_session(app_name):
    """
    This function helps in creating a spark session

    Parametes:
    ----------
    app_nale: str, Spark application name
    
    Returns:
    --------
    Spark Session

    """
    
    my_conf = SparkConf()
    my_conf.set("spark.app.name", app_name)
    my_conf.set("spark.master", "local[*]")

    spark = SparkSession.builder.config(conf=my_conf).getOrCreate()
    return spark

